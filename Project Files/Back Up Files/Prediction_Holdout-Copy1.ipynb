{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "from geopy.distance import distance\n",
    "import scipy.stats as stats\n",
    "from scipy import stats \n",
    "from math import sqrt\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.formula.api import ols \n",
    "import matplotlib.pyplot as plt   \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model \n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm \n",
    "import pickle \n",
    "\n",
    "\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "sns.set(style='darkgrid', color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_file = open('scaler.pickle','rb')\n",
    "final_scaler = pickle.load(scaler_file)\n",
    "model_file = open('model.pickle','rb')\n",
    "final_model = pickle.load(model_file)\n",
    "scaler_file.close()\n",
    "model_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.69215117e+02,  2.74118179e+01,  3.04674135e+02, -2.82578061e+04,\n",
       "        6.14765398e+04,  1.45718969e+02,  1.88674775e-01, -8.12278359e+03,\n",
       "       -3.15651767e+05,  4.84114365e+04, -1.18852601e+04, -1.11861760e+05,\n",
       "       -1.68314024e+04, -9.21783298e+05,  1.69215117e+02, -8.87670977e+04,\n",
       "       -4.27864888e+02, -5.82399688e+04,  6.11458331e+03,  5.25532503e+04,\n",
       "       -1.39339288e+05, -4.04507100e+04,  1.29314002e+05,  5.04759953e+04,\n",
       "       -8.72557994e+04, -6.66755012e+04, -1.02550049e+05,  5.07599491e+05,\n",
       "        4.34767884e+04,  3.11571592e+04,  4.57804734e+03,  1.89048832e+04,\n",
       "        1.12689269e+04, -9.74779374e+04, -4.25401215e+03, -5.84338261e+04,\n",
       "        3.26436686e+04, -1.14316120e+05,  5.13840310e+04,  1.48483078e+04,\n",
       "       -1.20687418e+05,  6.02653458e+04, -1.18057911e+05, -1.32299319e+05,\n",
       "       -1.22569543e+05,  8.11446063e+04, -6.42215277e+04, -4.56527161e+04,\n",
       "        9.99416702e+05,  1.98277151e+05, -9.11039786e+04,  7.01076591e+04,\n",
       "        1.72170470e+04,  3.47102750e+04, -1.36847953e+05, -1.19692011e+05,\n",
       "       -1.27681332e+05, -9.85579432e+04,  2.34428975e+04, -9.23900572e+04,\n",
       "       -5.40742152e+04, -8.22824545e+02,  6.48019468e+03, -6.60103638e+04,\n",
       "       -9.20766907e+04,  1.93614878e+05,  5.98850925e+04,  1.77031647e+05,\n",
       "       -1.16173721e+05,  6.93341951e+04, -1.30314702e+05,  1.91255413e+05,\n",
       "        3.20128404e+05,  4.75906048e+04,  3.94934720e+04,  4.16683009e+04,\n",
       "       -7.56221649e+04,  2.09596185e+05,  6.04896371e+04, -8.13676678e+04,\n",
       "       -5.10682412e+04, -1.08171622e+05,  3.96256116e+04,  2.40879148e+04,\n",
       "       -1.23946969e+05, -1.30582738e+05, -1.20951361e+05, -1.29606475e+05,\n",
       "       -1.75721961e+05, -2.33775758e+04, -1.82029376e+05, -1.64104744e+05,\n",
       "       -1.39282647e+05,  8.53064790e+04,  6.29726184e+04,  3.25524682e+03])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in hold data and niche file\n",
    "\n",
    "hnj = pd.read_csv('kc_house_data_test_features.csv')  #insert prediction file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drops unneeded columns\n",
    "def drop_uneeded_columns(df): \n",
    "    unwanted_columns_lists= ['Unnamed: 0', 'id', 'date',\n",
    "                             'sqft_living15', 'sqft_lot15'] \n",
    "    for c in unwanted_columns_lists: \n",
    "        del df[c] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call function above\n",
    "drop_uneeded_columns(hnj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function caps bedrooms and bathrooms \n",
    "def cap_ba_bd(row):\n",
    "    if row['bedrooms'] > 11:\n",
    "        row['bedrooms'] = 3 #column average\n",
    "    if row['bedrooms'] > 9:\n",
    "        row['bedrooms'] = 10\n",
    "    if row['bathrooms'] < 1:\n",
    "        row['bathrooms'] = 1\n",
    "    return row  \n",
    "\n",
    "hnj = hnj.apply(cap_ba_bd, axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = hnj.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates the distance to a popular park in seattle and creates the column \n",
    "clean_data['distance_to_gas_works'] = np.nan\n",
    "def dist_to_gas_work(row): \n",
    "    gas_works_park = (47.6456, -122.3344) \n",
    "    coord = (row['lat'], row['long']) \n",
    "    dist = distance(gas_works_park, coord).miles \n",
    "    row['distance_to_gas_works'] = (round((dist), 2))\n",
    "    return row \n",
    "\n",
    "clean_data = clean_data.apply(dist_to_gas_work, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates the ratio of bedrooms to bathrooms\n",
    "clean_data['bath_to_bed'] = np.nan\n",
    "def b_b_column(row): \n",
    "    if row['bedrooms'] == 0: \n",
    "         bath_bed = row['bathrooms']/1\n",
    "    else:\n",
    "        bath_bed = row['bathrooms']/row['bedrooms'] \n",
    "    ratio_ab = abs(bath_bed) \n",
    "    row['bath_to_bed'] = ratio_ab \n",
    "    return row \n",
    "\n",
    "clean_data = clean_data.apply(b_b_column, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a binary column that denotes whether a home has the golden ratio (or is within 10% of it)\n",
    "clean_data['golden_ratio'] = np.nan\n",
    "def golden_ratio(row): \n",
    "    golden_ratio = 2/3\n",
    "    golden_ratio_u = golden_ratio + (golden_ratio*.10) \n",
    "    golden_ratio_l = golden_ratio - (golden_ratio*.10) \n",
    "    if row['bath_to_bed'] >= golden_ratio_l:\n",
    "        if row['bath_to_bed'] <= golden_ratio_u: \n",
    "            row['golden_ratio'] = 1  \n",
    "        else: \n",
    "            row['golden_ratio'] = 0 \n",
    "    else: \n",
    "        row['golden_ratio'] = 0 \n",
    "    return row \n",
    "\n",
    "clean_data = clean_data.apply(golden_ratio, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a populates a sqft living to lot ration \n",
    "clean_data['sqft_li_to_sqft_lo'] = np.nan\n",
    "def li_lo_column(row): \n",
    "    living__to_lot = row['sqft_living']/row['sqft_lot']\n",
    "    ratio_ab = abs(living__to_lot) \n",
    "    row['sqft_li_to_sqft_lo'] = ratio_ab \n",
    "    return row  \n",
    "clean_data = clean_data.apply(li_lo_column, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates and populates a new row tha combine grade and condition while slightly weighing grade by 25%\n",
    "clean_data['score'] = np.nan\n",
    "def grade_n_cond(row): \n",
    "    new_grade = row['grade']*1.25\n",
    "    score = new_grade + row['condition']\n",
    "    row['score'] = score \n",
    "    return row \n",
    "\n",
    "clean_data = clean_data.apply(grade_n_cond, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates and populates a new column that shows when the house was last changed whether it was when it was built or renovated\n",
    "clean_data['year_updated'] = np.nan\n",
    "def year_changed(row): \n",
    "    if row['yr_renovated'] > 1:\n",
    "        row['year_updated'] = row['yr_renovated']  \n",
    "    else: \n",
    "        row['year_updated'] = row['yr_built']\n",
    "    return row \n",
    "\n",
    "clean_data = clean_data.apply(year_changed, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a binary based on whether or not a home has a basement by noting if it includes a number in higher zero in the sqft_basement column\n",
    "clean_data['basement'] = clean_data['sqft_basement'].map(lambda x : 1 if x != 0 else 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Catagorizes homes by number of bedrooms \n",
    "clean_data['home_category'] = np.nan\n",
    "def home_cat(row): \n",
    "    if row['bedrooms'] < 2:\n",
    "        row['home_category'] = 'starter'  \n",
    "    elif row['bedrooms'] < 5: \n",
    "        row['home_category'] = 'small_family' \n",
    "    elif row['bedrooms'] < 9: \n",
    "        row['home_category'] = 'large_family'\n",
    "    else:\n",
    "        row['bedrooms'] >= 9\n",
    "        row['home_category'] = 'mansion'\n",
    "    return row \n",
    "\n",
    "clean_data = clean_data.apply(home_cat, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Catagorizes home based on score \n",
    "clean_data['score_cat'] = np.nan\n",
    "def score_cat(row): \n",
    "    if row['score'] <= 11.5:\n",
    "        row['score_cat'] = 'low'  \n",
    "    elif row['score'] <= 12: \n",
    "        row['score_cat'] = 'low_mid' \n",
    "    elif row['score'] <= 13: \n",
    "        row['score_cat'] = 'high_mid'\n",
    "    else:\n",
    "        row['score_cat'] = 'high_end'\n",
    "    return row \n",
    "\n",
    "clean_data = clean_data.apply(score_cat, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates the last year updated from either year built or year renovated and populates it\n",
    "clean_data['years_since_updated'] = np.nan\n",
    "def years_old(row):  \n",
    "    age = 2021 - row['year_updated'] \n",
    "    if age < 1: \n",
    "        row['years_since_updated'] = 1 \n",
    "    else: \n",
    "        row['years_since_updated'] = age\n",
    "    return row \n",
    "clean_data = clean_data.apply(years_old, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data2 = clean_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns that are no longer needed because new features have been created\n",
    "def drop_uneeded_columns2(df): \n",
    "    unwanted_columns_lists= ['grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated',\n",
    "        'long', 'lat', 'condition'] \n",
    "    for c in unwanted_columns_lists: \n",
    "        del df[c]  \n",
    "\n",
    "drop_uneeded_columns2(clean_data2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_data = clean_data2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turns out home category into dummy variables and drops the original column\n",
    "pf_data = pd.concat([pf_data, pd.get_dummies(pf_data['home_category'])], 1) \n",
    "pf_data = pf_data.drop(columns = 'home_category') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turns our score categories into dummy variables and drops the original column\n",
    "pf_data = pd.concat([pf_data, pd.get_dummies(pf_data['score_cat'])], 1)   \n",
    "pf_data = pf_data.drop(columns = 'score_cat') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turns zipcodes into dummy variables and drops original columns\n",
    "pf_data = pd.concat([pf_data, pd.get_dummies(pf_data['zipcode'])], 1)  \n",
    "pf_data = pf_data.drop(columns = 'zipcode') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_data2 = pf_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_data2['sqft_li_to_sqft_lo_score'] = pf_data2['score'] * pf_data2['sqft_li_to_sqft_lo'] \n",
    "pf_data2['score^2'] = pf_data2['score'] * pf_data2['score'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feats = pf_data2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates interaction between sqft_living and basement binary value\n",
    "\n",
    "all_feats['s_b_b'] = all_feats['basement'] * all_feats['sqft_living'] \n",
    "\n",
    "#Creates interaction between waterfront and sqft_living\n",
    "\n",
    "all_feats['w_b_s'] = all_feats['waterfront'] * all_feats['sqft_living']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_transform_df = all_feats.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "af_list = af_list =  [ 'years_since_updated',  's_b_b','w_b_s',              \n",
    "                    'bedrooms',             'bathrooms',\n",
    "                 'sqft_living',              'sqft_lot',\n",
    "                      'floors',            'waterfront',\n",
    "                        'view', 'distance_to_gas_works',\n",
    "                 'bath_to_bed',          'golden_ratio',\n",
    "          'sqft_li_to_sqft_lo',                \n",
    "                'year_updated',              'basement',\n",
    "                'large_family',               'mansion',\n",
    "                'small_family',               'starter',\n",
    "                    'high_end',              'high_mid',\n",
    "                         'low',               'low_mid',\n",
    "                       98001.0,                 98002.0,\n",
    "                       98003.0,                 98004.0,\n",
    "                       98005.0,                 98006.0,\n",
    "                       98007.0,                 98008.0,\n",
    "                       98010.0,                 98011.0,\n",
    "                       98014.0,                 98019.0,\n",
    "                       98022.0,                 98023.0,\n",
    "                       98024.0,                 98027.0,\n",
    "                       98028.0,                 98029.0,\n",
    "                       98030.0,                 98031.0,\n",
    "                       98032.0,                 98033.0,\n",
    "                       98034.0,                 98038.0,\n",
    "                       98039.0,                 98040.0,\n",
    "                       98042.0,                 98045.0,\n",
    "                       98052.0,                 98053.0,\n",
    "                       98055.0,                 98056.0,\n",
    "                       98058.0,                 98059.0,\n",
    "                       98065.0,                 98070.0,\n",
    "                       98072.0,                 98074.0,\n",
    "                       98075.0,                 98077.0,\n",
    "                       98092.0,                 98102.0,\n",
    "                       98103.0,                 98105.0,\n",
    "                       98106.0,                 98107.0,\n",
    "                       98108.0,                 98109.0,\n",
    "                       98112.0,                 98115.0,\n",
    "                       98116.0,                 98117.0,\n",
    "                       98118.0,                 98119.0,\n",
    "                       98122.0,                 98125.0,\n",
    "                       98126.0,                 98133.0,\n",
    "                       98136.0,                 98144.0,\n",
    "                       98146.0,                 98148.0,\n",
    "                       98155.0,                 98166.0,\n",
    "                       98168.0,                 98177.0,\n",
    "                       98178.0,                 98188.0,\n",
    "                       98198.0,                 98199.0, \n",
    "              'sqft_li_to_sqft_lo_score',                         'score^2',\n",
    "                        ]   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_transform_df = after_transform_df[af_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4323, 96)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_transform_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_holdout = final_scaler.transform(after_transform_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_answers = final_model.predict(after_transform_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([549579.13381643, 549579.13381643, 365121.17073068, 303114.10428469,\n",
       "       524034.77287925, 594825.9665031 , 282290.54995036, 252853.05178678,\n",
       "       450426.33229791, 304122.36555174])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_answers[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(final_answers)\n",
    "df.to_csv('housing_predictions_Jiji.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
